{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check resource availability and Import relavent packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import requests\n",
    "import io\n",
    "import csv\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "import timm \n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# check if cuda is available\n",
    "print(torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convit_base.fb_in1k',\n",
       " 'convit_small.fb_in1k',\n",
       " 'convit_tiny.fb_in1k',\n",
       " 'crossvit_9_240.in1k',\n",
       " 'crossvit_9_dagger_240.in1k',\n",
       " 'crossvit_15_240.in1k',\n",
       " 'crossvit_15_dagger_240.in1k',\n",
       " 'crossvit_15_dagger_408.in1k',\n",
       " 'crossvit_18_240.in1k',\n",
       " 'crossvit_18_dagger_240.in1k',\n",
       " 'crossvit_18_dagger_408.in1k',\n",
       " 'crossvit_base_240.in1k',\n",
       " 'crossvit_small_240.in1k',\n",
       " 'crossvit_tiny_240.in1k',\n",
       " 'davit_base.msft_in1k',\n",
       " 'davit_small.msft_in1k',\n",
       " 'davit_tiny.msft_in1k',\n",
       " 'efficientvit_b0.r224_in1k',\n",
       " 'efficientvit_b1.r224_in1k',\n",
       " 'efficientvit_b1.r256_in1k',\n",
       " 'efficientvit_b1.r288_in1k',\n",
       " 'efficientvit_b2.r224_in1k',\n",
       " 'efficientvit_b2.r256_in1k',\n",
       " 'efficientvit_b2.r288_in1k',\n",
       " 'efficientvit_b3.r224_in1k',\n",
       " 'efficientvit_b3.r256_in1k',\n",
       " 'efficientvit_b3.r288_in1k',\n",
       " 'efficientvit_l1.r224_in1k',\n",
       " 'efficientvit_l2.r224_in1k',\n",
       " 'efficientvit_l2.r256_in1k',\n",
       " 'efficientvit_l2.r288_in1k',\n",
       " 'efficientvit_l2.r384_in1k',\n",
       " 'efficientvit_l3.r224_in1k',\n",
       " 'efficientvit_l3.r256_in1k',\n",
       " 'efficientvit_l3.r320_in1k',\n",
       " 'efficientvit_l3.r384_in1k',\n",
       " 'efficientvit_m0.r224_in1k',\n",
       " 'efficientvit_m1.r224_in1k',\n",
       " 'efficientvit_m2.r224_in1k',\n",
       " 'efficientvit_m3.r224_in1k',\n",
       " 'efficientvit_m4.r224_in1k',\n",
       " 'efficientvit_m5.r224_in1k',\n",
       " 'fastvit_ma36.apple_dist_in1k',\n",
       " 'fastvit_ma36.apple_in1k',\n",
       " 'fastvit_s12.apple_dist_in1k',\n",
       " 'fastvit_s12.apple_in1k',\n",
       " 'fastvit_sa12.apple_dist_in1k',\n",
       " 'fastvit_sa12.apple_in1k',\n",
       " 'fastvit_sa24.apple_dist_in1k',\n",
       " 'fastvit_sa24.apple_in1k',\n",
       " 'fastvit_sa36.apple_dist_in1k',\n",
       " 'fastvit_sa36.apple_in1k',\n",
       " 'fastvit_t8.apple_dist_in1k',\n",
       " 'fastvit_t8.apple_in1k',\n",
       " 'fastvit_t12.apple_dist_in1k',\n",
       " 'fastvit_t12.apple_in1k',\n",
       " 'flexivit_base.300ep_in1k',\n",
       " 'flexivit_base.300ep_in21k',\n",
       " 'flexivit_base.600ep_in1k',\n",
       " 'flexivit_base.1000ep_in21k',\n",
       " 'flexivit_base.1200ep_in1k',\n",
       " 'flexivit_base.patch16_in21k',\n",
       " 'flexivit_base.patch30_in21k',\n",
       " 'flexivit_large.300ep_in1k',\n",
       " 'flexivit_large.600ep_in1k',\n",
       " 'flexivit_large.1200ep_in1k',\n",
       " 'flexivit_small.300ep_in1k',\n",
       " 'flexivit_small.600ep_in1k',\n",
       " 'flexivit_small.1200ep_in1k',\n",
       " 'gcvit_base.in1k',\n",
       " 'gcvit_small.in1k',\n",
       " 'gcvit_tiny.in1k',\n",
       " 'gcvit_xtiny.in1k',\n",
       " 'gcvit_xxtiny.in1k',\n",
       " 'levit_128.fb_dist_in1k',\n",
       " 'levit_128s.fb_dist_in1k',\n",
       " 'levit_192.fb_dist_in1k',\n",
       " 'levit_256.fb_dist_in1k',\n",
       " 'levit_384.fb_dist_in1k',\n",
       " 'levit_conv_128.fb_dist_in1k',\n",
       " 'levit_conv_128s.fb_dist_in1k',\n",
       " 'levit_conv_192.fb_dist_in1k',\n",
       " 'levit_conv_256.fb_dist_in1k',\n",
       " 'levit_conv_384.fb_dist_in1k',\n",
       " 'maxvit_base_tf_224.in1k',\n",
       " 'maxvit_base_tf_224.in21k',\n",
       " 'maxvit_base_tf_384.in1k',\n",
       " 'maxvit_base_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_base_tf_512.in1k',\n",
       " 'maxvit_base_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_224.in1k',\n",
       " 'maxvit_large_tf_224.in21k',\n",
       " 'maxvit_large_tf_384.in1k',\n",
       " 'maxvit_large_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_large_tf_512.in1k',\n",
       " 'maxvit_large_tf_512.in21k_ft_in1k',\n",
       " 'maxvit_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxvit_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
       " 'maxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_pico_rw_256.sw_in1k',\n",
       " 'maxvit_rmlp_small_rw_224.sw_in1k',\n",
       " 'maxvit_rmlp_tiny_rw_256.sw_in1k',\n",
       " 'maxvit_small_tf_224.in1k',\n",
       " 'maxvit_small_tf_384.in1k',\n",
       " 'maxvit_small_tf_512.in1k',\n",
       " 'maxvit_tiny_rw_224.sw_in1k',\n",
       " 'maxvit_tiny_tf_224.in1k',\n",
       " 'maxvit_tiny_tf_384.in1k',\n",
       " 'maxvit_tiny_tf_512.in1k',\n",
       " 'maxvit_xlarge_tf_224.in21k',\n",
       " 'maxvit_xlarge_tf_384.in21k_ft_in1k',\n",
       " 'maxvit_xlarge_tf_512.in21k_ft_in1k',\n",
       " 'maxxvit_rmlp_nano_rw_256.sw_in1k',\n",
       " 'maxxvit_rmlp_small_rw_256.sw_in1k',\n",
       " 'maxxvitv2_nano_rw_256.sw_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k',\n",
       " 'maxxvitv2_rmlp_base_rw_224.sw_in12k_ft_in1k',\n",
       " 'maxxvitv2_rmlp_base_rw_384.sw_in12k_ft_in1k',\n",
       " 'mobilevit_s.cvnets_in1k',\n",
       " 'mobilevit_xs.cvnets_in1k',\n",
       " 'mobilevit_xxs.cvnets_in1k',\n",
       " 'mobilevitv2_050.cvnets_in1k',\n",
       " 'mobilevitv2_075.cvnets_in1k',\n",
       " 'mobilevitv2_100.cvnets_in1k',\n",
       " 'mobilevitv2_125.cvnets_in1k',\n",
       " 'mobilevitv2_150.cvnets_in1k',\n",
       " 'mobilevitv2_150.cvnets_in22k_ft_in1k',\n",
       " 'mobilevitv2_150.cvnets_in22k_ft_in1k_384',\n",
       " 'mobilevitv2_175.cvnets_in1k',\n",
       " 'mobilevitv2_175.cvnets_in22k_ft_in1k',\n",
       " 'mobilevitv2_175.cvnets_in22k_ft_in1k_384',\n",
       " 'mobilevitv2_200.cvnets_in1k',\n",
       " 'mobilevitv2_200.cvnets_in22k_ft_in1k',\n",
       " 'mobilevitv2_200.cvnets_in22k_ft_in1k_384',\n",
       " 'mvitv2_base.fb_in1k',\n",
       " 'mvitv2_base_cls.fb_inw21k',\n",
       " 'mvitv2_huge_cls.fb_inw21k',\n",
       " 'mvitv2_large.fb_in1k',\n",
       " 'mvitv2_large_cls.fb_inw21k',\n",
       " 'mvitv2_small.fb_in1k',\n",
       " 'mvitv2_tiny.fb_in1k',\n",
       " 'nextvit_base.bd_in1k',\n",
       " 'nextvit_base.bd_in1k_384',\n",
       " 'nextvit_base.bd_ssld_6m_in1k',\n",
       " 'nextvit_base.bd_ssld_6m_in1k_384',\n",
       " 'nextvit_large.bd_in1k',\n",
       " 'nextvit_large.bd_in1k_384',\n",
       " 'nextvit_large.bd_ssld_6m_in1k',\n",
       " 'nextvit_large.bd_ssld_6m_in1k_384',\n",
       " 'nextvit_small.bd_in1k',\n",
       " 'nextvit_small.bd_in1k_384',\n",
       " 'nextvit_small.bd_ssld_6m_in1k',\n",
       " 'nextvit_small.bd_ssld_6m_in1k_384',\n",
       " 'repvit_m0_9.dist_300e_in1k',\n",
       " 'repvit_m0_9.dist_450e_in1k',\n",
       " 'repvit_m1.dist_in1k',\n",
       " 'repvit_m1_0.dist_300e_in1k',\n",
       " 'repvit_m1_0.dist_450e_in1k',\n",
       " 'repvit_m1_1.dist_300e_in1k',\n",
       " 'repvit_m1_1.dist_450e_in1k',\n",
       " 'repvit_m1_5.dist_300e_in1k',\n",
       " 'repvit_m1_5.dist_450e_in1k',\n",
       " 'repvit_m2.dist_in1k',\n",
       " 'repvit_m2_3.dist_300e_in1k',\n",
       " 'repvit_m2_3.dist_450e_in1k',\n",
       " 'repvit_m3.dist_in1k',\n",
       " 'samvit_base_patch16.sa1b',\n",
       " 'samvit_huge_patch16.sa1b',\n",
       " 'samvit_large_patch16.sa1b',\n",
       " 'tiny_vit_5m_224.dist_in22k',\n",
       " 'tiny_vit_5m_224.dist_in22k_ft_in1k',\n",
       " 'tiny_vit_5m_224.in1k',\n",
       " 'tiny_vit_11m_224.dist_in22k',\n",
       " 'tiny_vit_11m_224.dist_in22k_ft_in1k',\n",
       " 'tiny_vit_11m_224.in1k',\n",
       " 'tiny_vit_21m_224.dist_in22k',\n",
       " 'tiny_vit_21m_224.dist_in22k_ft_in1k',\n",
       " 'tiny_vit_21m_224.in1k',\n",
       " 'tiny_vit_21m_384.dist_in22k_ft_in1k',\n",
       " 'tiny_vit_21m_512.dist_in22k_ft_in1k',\n",
       " 'vit_base_patch8_224.augreg2_in21k_ft_in1k',\n",
       " 'vit_base_patch8_224.augreg_in21k',\n",
       " 'vit_base_patch8_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch8_224.dino',\n",
       " 'vit_base_patch14_dinov2.lvd142m',\n",
       " 'vit_base_patch14_reg4_dinov2.lvd142m',\n",
       " 'vit_base_patch16_224.augreg2_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.augreg_in1k',\n",
       " 'vit_base_patch16_224.augreg_in21k',\n",
       " 'vit_base_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.dino',\n",
       " 'vit_base_patch16_224.mae',\n",
       " 'vit_base_patch16_224.orig_in21k',\n",
       " 'vit_base_patch16_224.orig_in21k_ft_in1k',\n",
       " 'vit_base_patch16_224.sam_in1k',\n",
       " 'vit_base_patch16_224_miil.in21k',\n",
       " 'vit_base_patch16_224_miil.in21k_ft_in1k',\n",
       " 'vit_base_patch16_384.augreg_in1k',\n",
       " 'vit_base_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch16_384.orig_in21k_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.datacompxl',\n",
       " 'vit_base_patch16_clip_224.dfn2b',\n",
       " 'vit_base_patch16_clip_224.laion2b',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in12k',\n",
       " 'vit_base_patch16_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_224.metaclip_2pt5b',\n",
       " 'vit_base_patch16_clip_224.openai',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in1k',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in12k',\n",
       " 'vit_base_patch16_clip_224.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_384.laion2b_ft_in1k',\n",
       " 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_384.openai_ft_in1k',\n",
       " 'vit_base_patch16_clip_384.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch16_clip_quickgelu_224.metaclip_2pt5b',\n",
       " 'vit_base_patch16_clip_quickgelu_224.openai',\n",
       " 'vit_base_patch16_rpn_224.sw_in1k',\n",
       " 'vit_base_patch16_siglip_224.webli',\n",
       " 'vit_base_patch16_siglip_256.webli',\n",
       " 'vit_base_patch16_siglip_384.webli',\n",
       " 'vit_base_patch16_siglip_512.webli',\n",
       " 'vit_base_patch32_224.augreg_in1k',\n",
       " 'vit_base_patch32_224.augreg_in21k',\n",
       " 'vit_base_patch32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch32_224.orig_in21k',\n",
       " 'vit_base_patch32_224.sam_in1k',\n",
       " 'vit_base_patch32_384.augreg_in1k',\n",
       " 'vit_base_patch32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_base_patch32_clip_224.datacompxl',\n",
       " 'vit_base_patch32_clip_224.laion2b',\n",
       " 'vit_base_patch32_clip_224.laion2b_ft_in1k',\n",
       " 'vit_base_patch32_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_224.metaclip_2pt5b',\n",
       " 'vit_base_patch32_clip_224.openai',\n",
       " 'vit_base_patch32_clip_224.openai_ft_in1k',\n",
       " 'vit_base_patch32_clip_256.datacompxl',\n",
       " 'vit_base_patch32_clip_384.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_384.openai_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_448.laion2b_ft_in12k_in1k',\n",
       " 'vit_base_patch32_clip_quickgelu_224.metaclip_2pt5b',\n",
       " 'vit_base_patch32_clip_quickgelu_224.openai',\n",
       " 'vit_base_r50_s16_224.orig_in21k',\n",
       " 'vit_base_r50_s16_384.orig_in21k_ft_in1k',\n",
       " 'vit_giant_patch14_clip_224.laion2b',\n",
       " 'vit_giant_patch14_dinov2.lvd142m',\n",
       " 'vit_giant_patch14_reg4_dinov2.lvd142m',\n",
       " 'vit_giant_patch16_gap_224.in22k_ijepa',\n",
       " 'vit_gigantic_patch14_clip_224.laion2b',\n",
       " 'vit_huge_patch14_224.mae',\n",
       " 'vit_huge_patch14_224.orig_in21k',\n",
       " 'vit_huge_patch14_clip_224.dfn5b',\n",
       " 'vit_huge_patch14_clip_224.laion2b',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in1k',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in12k',\n",
       " 'vit_huge_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_huge_patch14_clip_224.metaclip_2pt5b',\n",
       " 'vit_huge_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
       " 'vit_huge_patch14_clip_378.dfn5b',\n",
       " 'vit_huge_patch14_clip_quickgelu_224.dfn5b',\n",
       " 'vit_huge_patch14_clip_quickgelu_224.metaclip_2pt5b',\n",
       " 'vit_huge_patch14_clip_quickgelu_378.dfn5b',\n",
       " 'vit_huge_patch14_gap_224.in1k_ijepa',\n",
       " 'vit_huge_patch14_gap_224.in22k_ijepa',\n",
       " 'vit_huge_patch16_gap_448.in1k_ijepa',\n",
       " 'vit_large_patch14_clip_224.datacompxl',\n",
       " 'vit_large_patch14_clip_224.dfn2b',\n",
       " 'vit_large_patch14_clip_224.laion2b',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in1k',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in12k',\n",
       " 'vit_large_patch14_clip_224.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_224.metaclip_2pt5b',\n",
       " 'vit_large_patch14_clip_224.openai',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in1k',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in12k',\n",
       " 'vit_large_patch14_clip_224.openai_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_336.laion2b_ft_in1k',\n",
       " 'vit_large_patch14_clip_336.laion2b_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_336.openai',\n",
       " 'vit_large_patch14_clip_336.openai_ft_in12k_in1k',\n",
       " 'vit_large_patch14_clip_quickgelu_224.dfn2b',\n",
       " 'vit_large_patch14_clip_quickgelu_224.metaclip_2pt5b',\n",
       " 'vit_large_patch14_clip_quickgelu_224.openai',\n",
       " 'vit_large_patch14_clip_quickgelu_336.openai',\n",
       " 'vit_large_patch14_dinov2.lvd142m',\n",
       " 'vit_large_patch14_reg4_dinov2.lvd142m',\n",
       " 'vit_large_patch16_224.augreg_in21k',\n",
       " 'vit_large_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_large_patch16_224.mae',\n",
       " 'vit_large_patch16_224.orig_in21k',\n",
       " 'vit_large_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_large_patch16_siglip_256.webli',\n",
       " 'vit_large_patch16_siglip_384.webli',\n",
       " 'vit_large_patch32_224.orig_in21k',\n",
       " 'vit_large_patch32_384.orig_in21k_ft_in1k',\n",
       " 'vit_large_r50_s32_224.augreg_in21k',\n",
       " 'vit_large_r50_s32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_large_r50_s32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_medium_patch16_gap_240.sw_in12k',\n",
       " 'vit_medium_patch16_gap_256.sw_in12k_ft_in1k',\n",
       " 'vit_medium_patch16_gap_384.sw_in12k_ft_in1k',\n",
       " 'vit_relpos_base_patch16_224.sw_in1k',\n",
       " 'vit_relpos_base_patch16_clsgap_224.sw_in1k',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_224.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_cls_224.sw_in1k',\n",
       " 'vit_relpos_medium_patch16_rpn_224.sw_in1k',\n",
       " 'vit_relpos_small_patch16_224.sw_in1k',\n",
       " 'vit_small_patch8_224.dino',\n",
       " 'vit_small_patch14_dinov2.lvd142m',\n",
       " 'vit_small_patch14_reg4_dinov2.lvd142m',\n",
       " 'vit_small_patch16_224.augreg_in1k',\n",
       " 'vit_small_patch16_224.augreg_in21k',\n",
       " 'vit_small_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch16_224.dino',\n",
       " 'vit_small_patch16_384.augreg_in1k',\n",
       " 'vit_small_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch32_224.augreg_in21k',\n",
       " 'vit_small_patch32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_patch32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_small_r26_s32_224.augreg_in21k',\n",
       " 'vit_small_r26_s32_224.augreg_in21k_ft_in1k',\n",
       " 'vit_small_r26_s32_384.augreg_in21k_ft_in1k',\n",
       " 'vit_so400m_patch14_siglip_224.webli',\n",
       " 'vit_so400m_patch14_siglip_384.webli',\n",
       " 'vit_srelpos_medium_patch16_224.sw_in1k',\n",
       " 'vit_srelpos_small_patch16_224.sw_in1k',\n",
       " 'vit_tiny_patch16_224.augreg_in21k',\n",
       " 'vit_tiny_patch16_224.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_patch16_384.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_r_s16_p8_224.augreg_in21k',\n",
       " 'vit_tiny_r_s16_p8_224.augreg_in21k_ft_in1k',\n",
       " 'vit_tiny_r_s16_p8_384.augreg_in21k_ft_in1k']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vit_models = timm.list_models('*vit*', pretrained=True)\n",
    "all_vit_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import create_dataset, create_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config \n",
    "input_size = 3, 224, 224\n",
    "img_size = 224\n",
    "num_classes = 15\n",
    "batch_size = 32\n",
    "\n",
    "interpolation = 'bicubic'\n",
    "DEFAULT_CROP_PCT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Dataset/images/train'\n",
    "val_dir = '../Dataset/images/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\n",
    "        'Normal': 0,\n",
    "        'Atelectasis': 1,\n",
    "        'Cardiomegaly': 2,\n",
    "        'Effusion': 3,\n",
    "        'Infiltration': 4,\n",
    "        'Mass': 5,\n",
    "        'Nodule': 6,\n",
    "        'Pneumonia': 7,\n",
    "        'Pneumothorax': 8,\n",
    "        'Consolidation': 9,\n",
    "        'Edema': 10,\n",
    "        'Emphysema': 11,\n",
    "        'Fibrosis': 12,\n",
    "        'Pleural_Thickening': 13,\n",
    "        'Hernia': 14,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 91295\n",
      "Validation set size: 13175\n"
     ]
    }
   ],
   "source": [
    "# create the train and eval datasets\n",
    "train_dataset = create_dataset(name='', root=train_dir, split='train', is_training=True, batch_size=batch_size, class_map = class_map)\n",
    "val_dataset = create_dataset(name='', root=val_dir, split='validation', is_training=False, batch_size=batch_size, class_map = class_map)\n",
    "train_len, val_len = len(train_dataset), len(val_dataset)\n",
    "print('Training set size: ' + str(train_len))\n",
    "print('Validation set size: ' + str(val_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize images to fit the input of pretrained model\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset.transform = train_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loaders \n",
    "loader_train = create_loader(\n",
    "        train_dataset,\n",
    "        input_size=input_size,\n",
    "        batch_size=batch_size,\n",
    "        is_training=True,\n",
    "        interpolation=interpolation,\n",
    "        num_workers=4)\n",
    "\n",
    "loader_val = create_loader(\n",
    "        val_dataset,\n",
    "        input_size=input_size,\n",
    "        batch_size=batch_size,\n",
    "        is_training=False,\n",
    "        interpolation=interpolation,\n",
    "        crop_pct=DEFAULT_CROP_PCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Normal': 0,\n",
       " 'Atelectasis': 1,\n",
       " 'Cardiomegaly': 2,\n",
       " 'Effusion': 3,\n",
       " 'Infiltration': 4,\n",
       " 'Mass': 5,\n",
       " 'Nodule': 6,\n",
       " 'Pneumonia': 7,\n",
       " 'Pneumothorax': 8,\n",
       " 'Consolidation': 9,\n",
       " 'Edema': 10,\n",
       " 'Emphysema': 11,\n",
       " 'Fibrosis': 12,\n",
       " 'Pleural_Thickening': 13,\n",
       " 'Hernia': 14}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if labels are loaded as defined\n",
    "train_dataset.reader.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 44379,\n",
       " 1: 7250,\n",
       " 2: 1505,\n",
       " 3: 7475,\n",
       " 4: 11958,\n",
       " 5: 3471,\n",
       " 6: 4067,\n",
       " 7: 761,\n",
       " 8: 2320,\n",
       " 9: 2485,\n",
       " 10: 1225,\n",
       " 11: 1236,\n",
       " 12: 1078,\n",
       " 13: 1954,\n",
       " 14: 131}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many images for each class. confirm if this number is correct to make sure images are loaded properly\n",
    "class_images_num = dict(zip(class_map.values(),[0]*15))\n",
    "for i in range(len(train_dataset.reader)):\n",
    "    _, class_idx = train_dataset.reader[i]\n",
    "    class_images_num[class_idx] += 1\n",
    "\n",
    "class_images_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'vit_base_r50_s16_224.orig_in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'vit_base_patch16_224.orig_in21k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_name = 'resnet50.a1_in1k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): HybridEmbed(\n",
       "    (backbone): ResNetV2(\n",
       "      (stem): Sequential(\n",
       "        (conv): StdConv2dSame(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\n",
       "        (norm): GroupNormAct(\n",
       "          32, 64, eps=1e-05, affine=True\n",
       "          (drop): Identity()\n",
       "          (act): ReLU(inplace=True)\n",
       "        )\n",
       "        (pool): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
       "      )\n",
       "      (stages): Sequential(\n",
       "        (0): ResNetStage(\n",
       "          (blocks): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (downsample): DownsampleConv(\n",
       "                (conv): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): GroupNormAct(\n",
       "                  32, 256, eps=1e-05, affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (conv1): StdConv2dSame(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 64, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 64, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 64, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 64, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 64, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 64, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResNetStage(\n",
       "          (blocks): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (downsample): DownsampleConv(\n",
       "                (conv): StdConv2dSame(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (norm): GroupNormAct(\n",
       "                  32, 512, eps=1e-05, affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (conv1): StdConv2dSame(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 128, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 128, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 512, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 128, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 128, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 512, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 128, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 128, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 512, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 128, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 128, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 512, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ResNetStage(\n",
       "          (blocks): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (downsample): DownsampleConv(\n",
       "                (conv): StdConv2dSame(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (norm): GroupNormAct(\n",
       "                  32, 1024, eps=1e-05, affine=True\n",
       "                  (drop): Identity()\n",
       "                  (act): Identity()\n",
       "                )\n",
       "              )\n",
       "              (conv1): StdConv2dSame(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (3): Bottleneck(\n",
       "              (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (4): Bottleneck(\n",
       "              (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (5): Bottleneck(\n",
       "              (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (6): Bottleneck(\n",
       "              (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (7): Bottleneck(\n",
       "              (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "            (8): Bottleneck(\n",
       "              (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm1): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm2): GroupNormAct(\n",
       "                32, 256, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): ReLU(inplace=True)\n",
       "              )\n",
       "              (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm3): GroupNormAct(\n",
       "                32, 1024, eps=1e-05, affine=True\n",
       "                (drop): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (act3): ReLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): Identity()\n",
       "      (head): ClassifierHead(\n",
       "        (global_pool): SelectAdaptivePool2d(pool_type=, flatten=Identity())\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Identity()\n",
       "        (flatten): Identity()\n",
       "      )\n",
       "    )\n",
       "    (proj): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (patch_drop): Identity()\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  (head): Linear(in_features=768, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = timm.create_model(model_name, pretrained=True, num_classes=num_classes) #, img_size=img_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) # if print 'cuda' then GPU is used\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weight_decay(model, weight_decay=1e-5, skip_list=()):\n",
    "    decay = []\n",
    "    no_decay = []\n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue  # frozen weights\n",
    "        if len(param.shape) == 1 or name.endswith(\".bias\") or name in skip_list:\n",
    "            no_decay.append(param)\n",
    "        else:\n",
    "            decay.append(param)\n",
    "    return [\n",
    "        {'params': no_decay, 'weight_decay': 0.},\n",
    "        {'params': decay, 'weight_decay': weight_decay}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_decay\n",
    "skip = {}\n",
    "if hasattr(model, 'no_weight_decay'):\n",
    "    skip = model.no_weight_decay()\n",
    "parameters = add_weight_decay(model, 0.0001, skip)\n",
    "weight_decay = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(parameters, momentum=0.9, nesterov=True, lr=0.01, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.scheduler import StepLRScheduler\n",
    "# setup learning rate schedule and starting epoch\n",
    "lr_scheduler = StepLRScheduler(optimizer, decay_t=30, decay_rate=0.1,\n",
    "               warmup_lr_init=0.0001, warmup_t=3, noise_range_t=None, noise_pct=0.67,\n",
    "               noise_std=1., noise_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model, eval_data):\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in eval_data:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            total_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            break\n",
    "    accuracy = total_correct / total_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "losses = [[]]\n",
    "accus_train = [[]]\n",
    "accus_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "current_datetime = datetime.now()\n",
    "date_time = str(current_datetime)[:-7].replace('-','').replace(':','').replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_result/model_pth/MODEL_FINETUNE_vit_base_r50_s16_224.orig_in21k_20240330_125921.pth'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = f'model_result/model_pth/MODEL_FINETUNE_{model_name}_{date_time}.pth'\n",
    "model_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_log_writer(s, end='\\r'):\n",
    "    with open(f'model_result/log/output_{model_name}_{date_time}.txt', 'a') as output_file:\n",
    "        output_file.write(s+'\\n')\n",
    "        print(s,end,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    output_log_writer(f'-------------------------------[Epoch {epoch+1}]---------------------------------')\n",
    "    output_log_writer(f'[Epoch {epoch+1}] Training...', end='')\n",
    "    for batch, (images, labels) in enumerate(loader_train):\n",
    "        print('=', end='')\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses[-1].append(loss.item()) # all losses for this epoch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            accus_train[-1].append(torch.sum(torch.max(outputs, dim=1)[1] == labels)) # all train accuracy for this epoch\n",
    "    \n",
    "    \n",
    "    print('\\r')\n",
    "    output_log_writer(f'[Epoch {epoch+1}] Computing Train Measurement...')\n",
    "    # save all batches loss\n",
    "    with open(f'model_result/measurement/batch_loss_{model_name}_{date_time}.csv', 'w') as b_loss_file:\n",
    "        writer = csv.writer(b_loss_file)\n",
    "        writer.writerow([epoch] + losses[-1])\n",
    "    # compute total loss after this epoch \n",
    "    losses[-1] = sum(losses[-1]) \n",
    "    # save epoch loss\n",
    "    with open(f'model_result/measurement/epoch_loss_{model_name}_{date_time}.csv', 'w') as e_loss_file:\n",
    "        writer = csv.writer(e_loss_file)\n",
    "        writer.writerow([epoch, losses[-1]])\n",
    "    losses.append([])\n",
    "    \n",
    "    # compute average accuracy after this epoch\n",
    "    accus_train[-1] = sum(accus_train[-1]) / train_len \n",
    "    with open(f'model_result/measurement/acc_train_{model_name}_{date_time}.csv', 'w') as acc_train_file:\n",
    "        writer = csv.writer(acc_train_file)\n",
    "        writer.writerow([epoch, float(accus_train[-1])])\n",
    "    accus_train.append([])\n",
    "\n",
    "    # step LR for next epoch\n",
    "    lr_scheduler.step(epoch + 1)\n",
    "    \n",
    "    output_log_writer(f'[Epoch {epoch+1}] Computing Validation Measurement...')\n",
    "    accus_val.append(eval_fn(model, loader_val))\n",
    "    with open(f'model_result/measurement/acc_val_{model_name}_{date_time}.csv', 'w') as acc_val_file:\n",
    "        writer = csv.writer(acc_val_file)\n",
    "        writer.writerow([epoch, accus_val[-1]])\n",
    "    \n",
    "    model.train() # slowest line\n",
    "\n",
    "    \n",
    "    # print evaludation\n",
    "    output_log_writer(f'[Epoch {epoch+1}] loss={losses[-2]:.2e} train accu={accus_train[-2]:.2%} validation accu={accus_val[-1]:.2%}')\n",
    "    \n",
    "    # save output log\n",
    "    \n",
    "        \n",
    "    # save model checkpoint\n",
    "    ckpt_save_path = f'model_result/model_checkpoint/MODEL_CKPT_{epoch:2d}_{model_name}_{date_time}.pt'\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': losses[-2],\n",
    "            }, ckpt_save_path)\n",
    "    output_log_writer(f'[Epoch {epoch+1}] Model checkpoint is saved.')\n",
    "\n",
    "        \n",
    "torch.save(model, model_save_path)\n",
    "output_log_writer('\\n\\nFinal model saved. Training Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-env",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
