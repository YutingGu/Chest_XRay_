{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train/val/test folders\n",
    "There is no label information included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'Dataset/images'\n",
    "train_dir_nl = 'Dataset/images/train_no_label'\n",
    "val_dir_nl = 'Dataset/images/validation_no_label'\n",
    "test_dir_nl = 'Dataset/images/test_no_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels  = open('Dataset/train_list.txt').read().split('\\n')\n",
    "val_labels  = open('Dataset/val_list.txt').read().split('\\n')\n",
    "test_labels  = open('Dataset/test_list.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating  Dataset/images/train_no_label\n",
      "Creating  Dataset/images/validation_no_label\n",
      "Creating  Dataset/images/test_no_label\n"
     ]
    }
   ],
   "source": [
    "# creating path to store images in folders(train/val/test)\n",
    "for path in [train_dir_nl, val_dir_nl, test_dir_nl]:\n",
    "    if os.path.exists(path)== False:\n",
    "        print('Creating ',path)\n",
    "        os.makedirs(path)\n",
    "    else: print('Existed path', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.remove('train_no_label')\n",
    "files.remove('validation_no_label')\n",
    "files.remove('test_no_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'train_no_label' in files or 'validation_no_label' in files or 'test_no_label' in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112120/112120 [05:13<00:00, 357.15it/s]\n"
     ]
    }
   ],
   "source": [
    "for file in tqdm(files):\n",
    "    source_file = os.path.join(source_dir, file)\n",
    "    if file in val_labels:\n",
    "        destination_file = os.path.join(val_dir_nl, file)\n",
    "    elif file in test_labels:\n",
    "        destination_file = os.path.join(test_dir_nl, file)\n",
    "    else:\n",
    "        destination_file = os.path.join(train_dir_nl, file)       \n",
    "    \n",
    "    shutil.move(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75770+10754+25596"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into class-label folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('Dataset/train_label.csv', index_col=False)\n",
    "val_label = pd.read_csv('Dataset/val_label.csv', index_col=False)\n",
    "test_label = pd.read_csv('Dataset/test_label.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_map = train_label.set_index('FileName').to_dict(orient='index')\n",
    "val_label_map = val_label.set_index('FileName').to_dict(orient='index')\n",
    "test_label_map = test_label.set_index('FileName').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Dataset/images/train'\n",
    "val_dir = 'Dataset/images/validation'\n",
    "test_dir = 'Dataset/images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete folders because for debugging.\n",
    "# DON'T run this cell unless you are sure you want to delete images and resplit images\n",
    "#!rm -rf Dataset/images/train\n",
    "#!rm -rf Dataset/images/validation\n",
    "#!rm -rf Dataset/images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating  Dataset/images/train/Normal\n",
      "Creating  Dataset/images/train/Atelectasis\n",
      "Creating  Dataset/images/train/Cardiomegaly\n",
      "Creating  Dataset/images/train/Effusion\n",
      "Creating  Dataset/images/train/Infiltration\n",
      "Creating  Dataset/images/train/Mass\n",
      "Creating  Dataset/images/train/Nodule\n",
      "Creating  Dataset/images/train/Pneumonia\n",
      "Creating  Dataset/images/train/Pneumothorax\n",
      "Creating  Dataset/images/train/Consolidation\n",
      "Creating  Dataset/images/train/Edema\n",
      "Creating  Dataset/images/train/Emphysema\n",
      "Creating  Dataset/images/train/Fibrosis\n",
      "Creating  Dataset/images/train/Pleural_Thickening\n",
      "Creating  Dataset/images/train/Hernia\n",
      "Creating  Dataset/images/validation/Normal\n",
      "Creating  Dataset/images/validation/Atelectasis\n",
      "Creating  Dataset/images/validation/Cardiomegaly\n",
      "Creating  Dataset/images/validation/Effusion\n",
      "Creating  Dataset/images/validation/Infiltration\n",
      "Creating  Dataset/images/validation/Mass\n",
      "Creating  Dataset/images/validation/Nodule\n",
      "Creating  Dataset/images/validation/Pneumonia\n",
      "Creating  Dataset/images/validation/Pneumothorax\n",
      "Creating  Dataset/images/validation/Consolidation\n",
      "Creating  Dataset/images/validation/Edema\n",
      "Creating  Dataset/images/validation/Emphysema\n",
      "Creating  Dataset/images/validation/Fibrosis\n",
      "Creating  Dataset/images/validation/Pleural_Thickening\n",
      "Creating  Dataset/images/validation/Hernia\n",
      "Creating  Dataset/images/test/Normal\n",
      "Creating  Dataset/images/test/Atelectasis\n",
      "Creating  Dataset/images/test/Cardiomegaly\n",
      "Creating  Dataset/images/test/Effusion\n",
      "Creating  Dataset/images/test/Infiltration\n",
      "Creating  Dataset/images/test/Mass\n",
      "Creating  Dataset/images/test/Nodule\n",
      "Creating  Dataset/images/test/Pneumonia\n",
      "Creating  Dataset/images/test/Pneumothorax\n",
      "Creating  Dataset/images/test/Consolidation\n",
      "Creating  Dataset/images/test/Edema\n",
      "Creating  Dataset/images/test/Emphysema\n",
      "Creating  Dataset/images/test/Fibrosis\n",
      "Creating  Dataset/images/test/Pleural_Thickening\n",
      "Creating  Dataset/images/test/Hernia\n"
     ]
    }
   ],
   "source": [
    "# creating path to store images in folders(train/val/test) with subfolders named by class-label\n",
    "for path in [train_dir, val_dir, test_dir]:\n",
    "    for label in ['Normal'] + list(train_label.columns[1:]): \n",
    "        path_label = path + '/' + label\n",
    "        if os.path.exists(path_label)== False:\n",
    "            print('Creating ',path_label)\n",
    "            os.makedirs(path_label)\n",
    "        else: print('Existed path', path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_label_pair = [(train_dir_nl,train_dir,train_label_map),\n",
    "                  (val_dir_nl,val_dir,val_label_map),\n",
    "                  (test_dir_nl,test_dir,test_label_map)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(train_dir_nl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'validation_no_label' in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Dataset/images/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 32763/75770 [19:50<33:33, 21.36it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|██████████| 75770/75770 [43:06<00:00, 29.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Dataset/images/validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10754/10754 [05:49<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Dataset/images/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25596/25596 [14:02<00:00, 30.39it/s]\n"
     ]
    }
   ],
   "source": [
    "for path_nl, path, label_map in path_label_pair:\n",
    "    print('Copying '+path)\n",
    "    files = os.listdir(path_nl)\n",
    "    for file in tqdm(files):\n",
    "        label_dict = label_map[file]\n",
    "        source_file = os.path.join(path_nl, file)\n",
    "        \n",
    "        # images without any diagnosis\n",
    "        if sum(label_map[file].values()) == 0:\n",
    "            path_label = path + '/Normal'\n",
    "            destination_file = os.path.join(path_label, file)\n",
    "            shutil.copy(source_file, destination_file)\n",
    "\n",
    "        # images with diagnosis\n",
    "        for class_label, class_index in label_dict.items():\n",
    "            if class_index == 1:\n",
    "                path_label = path + '/' + class_label\n",
    "                destination_file = os.path.join(path_label, file)\n",
    "                shutil.copy(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30G\tDataset/images/train_no_label\n",
      "36G\tDataset/images/train\n",
      "4.3G\tDataset/images/validation_no_label\n",
      "5.2G\tDataset/images/validation\n",
      "10G\tDataset/images/test_no_label\n",
      "15G\tDataset/images/test\n"
     ]
    }
   ],
   "source": [
    "!du -sh Dataset/images/train_no_label\n",
    "!du -sh Dataset/images/train\n",
    "!du -sh Dataset/images/validation_no_label\n",
    "!du -sh Dataset/images/validation\n",
    "!du -sh Dataset/images/test_no_label\n",
    "!du -sh Dataset/images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-env",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
