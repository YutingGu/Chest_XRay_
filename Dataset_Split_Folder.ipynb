{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train/val/test folders\n",
    "There is no label information included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'Dataset/images'\n",
    "train_dir_nl = 'Dataset/images/train_no_label'\n",
    "val_dir_nl = 'Dataset/images/validation_no_label'\n",
    "test_dir_nl = 'Dataset/images/test_no_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels  = open('Dataset/train_list.txt').read().split('\\n')\n",
    "val_labels  = open('Dataset/val_list.txt').read().split('\\n')\n",
    "test_labels  = open('Dataset/test_list.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed path Dataset/images/train_no_label\n",
      "Existed path Dataset/images/validation_no_label\n",
      "Existed path Dataset/images/test_no_label\n"
     ]
    }
   ],
   "source": [
    "# creating path to store images in folders(train/val/test)\n",
    "for path in [train_dir_nl, val_dir_nl, test_dir_nl]:\n",
    "    if os.path.exists(path)== False:\n",
    "        print('Creating ',path)\n",
    "        os.makedirs(path)\n",
    "    else: print('Existed path', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(source_dir)\n",
    "for file in tqdm(files):\n",
    "    source_file = os.path.join(source_dir, file)\n",
    "    if file in val_labels:\n",
    "        destination_file = os.path.join(val_dir_nl, file)\n",
    "    elif file in test_labels:\n",
    "        destination_file = os.path.join(test_dir_nl, file)\n",
    "    else:\n",
    "        destination_file = os.path.join(train_dir_nl, file)\n",
    "        \n",
    "    shutil.move(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into class-label folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('Dataset/train_label.csv', index_col=False)\n",
    "val_label = pd.read_csv('Dataset/val_label.csv', index_col=False)\n",
    "test_label = pd.read_csv('Dataset/test_label.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_map = train_label.set_index('FileName').to_dict(orient='index')\n",
    "val_label_map = val_label.set_index('FileName').to_dict(orient='index')\n",
    "test_label_map = test_label.set_index('FileName').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Dataset/images/train'\n",
    "val_dir = 'Dataset/images/validation'\n",
    "test_dir = 'Dataset/images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete folders because for debugging.\n",
    "# DON'T run this cell unless you are sure you want to delete images and resplit images\n",
    "#!rm -rf Dataset/images/train\n",
    "#!rm -rf Dataset/images/validation\n",
    "#!rm -rf Dataset/images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating  Dataset/images/train/Normal\n",
      "Creating  Dataset/images/train/Atelectasis\n",
      "Creating  Dataset/images/train/Cardiomegaly\n",
      "Creating  Dataset/images/train/Effusion\n",
      "Creating  Dataset/images/train/Infiltration\n",
      "Creating  Dataset/images/train/Mass\n",
      "Creating  Dataset/images/train/Nodule\n",
      "Creating  Dataset/images/train/Pneumonia\n",
      "Creating  Dataset/images/train/Pneumothorax\n",
      "Creating  Dataset/images/train/Consolidation\n",
      "Creating  Dataset/images/train/Edema\n",
      "Creating  Dataset/images/train/Emphysema\n",
      "Creating  Dataset/images/train/Fibrosis\n",
      "Creating  Dataset/images/train/Pleural_Thickening\n",
      "Creating  Dataset/images/train/Hernia\n",
      "Creating  Dataset/images/validation/Normal\n",
      "Creating  Dataset/images/validation/Atelectasis\n",
      "Creating  Dataset/images/validation/Cardiomegaly\n",
      "Creating  Dataset/images/validation/Effusion\n",
      "Creating  Dataset/images/validation/Infiltration\n",
      "Creating  Dataset/images/validation/Mass\n",
      "Creating  Dataset/images/validation/Nodule\n",
      "Creating  Dataset/images/validation/Pneumonia\n",
      "Creating  Dataset/images/validation/Pneumothorax\n",
      "Creating  Dataset/images/validation/Consolidation\n",
      "Creating  Dataset/images/validation/Edema\n",
      "Creating  Dataset/images/validation/Emphysema\n",
      "Creating  Dataset/images/validation/Fibrosis\n",
      "Creating  Dataset/images/validation/Pleural_Thickening\n",
      "Creating  Dataset/images/validation/Hernia\n",
      "Creating  Dataset/images/test/Normal\n",
      "Creating  Dataset/images/test/Atelectasis\n",
      "Creating  Dataset/images/test/Cardiomegaly\n",
      "Creating  Dataset/images/test/Effusion\n",
      "Creating  Dataset/images/test/Infiltration\n",
      "Creating  Dataset/images/test/Mass\n",
      "Creating  Dataset/images/test/Nodule\n",
      "Creating  Dataset/images/test/Pneumonia\n",
      "Creating  Dataset/images/test/Pneumothorax\n",
      "Creating  Dataset/images/test/Consolidation\n",
      "Creating  Dataset/images/test/Edema\n",
      "Creating  Dataset/images/test/Emphysema\n",
      "Creating  Dataset/images/test/Fibrosis\n",
      "Creating  Dataset/images/test/Pleural_Thickening\n",
      "Creating  Dataset/images/test/Hernia\n"
     ]
    }
   ],
   "source": [
    "# creating path to store images in folders(train/val/test) with subfolders named by class-label\n",
    "for path in [train_dir, val_dir, test_dir]:\n",
    "    for label in ['Normal'] + list(train_label.columns[1:]): \n",
    "        path_label = path + '/' + label\n",
    "        if os.path.exists(path_label)== False:\n",
    "            print('Creating ',path_label)\n",
    "            os.makedirs(path_label)\n",
    "        else: print('Existed path', path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_label_pair = [(train_dir_nl,train_dir,train_label_map),\n",
    "                  (val_dir_nl,val_dir,val_label_map),\n",
    "                  (test_dir_nl,test_dir,test_label_map)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Dataset/images/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75770/75770 [39:04<00:00, 32.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Dataset/images/validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10754/10754 [05:52<00:00, 30.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Dataset/images/test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25596/25596 [13:47<00:00, 30.95it/s]\n"
     ]
    }
   ],
   "source": [
    "for path_nl, path, label_map in path_label_pair:\n",
    "    print('Copying '+path)\n",
    "    files = os.listdir(path_nl)\n",
    "    for file in tqdm(files):\n",
    "        label_dict = label_map[file]\n",
    "        source_file = os.path.join(path_nl, file)\n",
    "        \n",
    "        # images without any diagnosis\n",
    "        if sum(label_map[file].values()) == 0:\n",
    "            path_label = path + '/Normal'\n",
    "            destination_file = os.path.join(path_label, file)\n",
    "            shutil.copy(source_file, destination_file)\n",
    "\n",
    "        # images with diagnosis\n",
    "        for class_label, class_index in label_dict.items():\n",
    "            if class_index == 1:\n",
    "                path_label = path + '/' + class_label\n",
    "                destination_file = os.path.join(path_label, file)\n",
    "                shutil.copy(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30G\tDataset/images/train_no_label\n",
      "36G\tDataset/images/train\n",
      "4.3G\tDataset/images/validation_no_label\n",
      "5.2G\tDataset/images/validation\n",
      "10G\tDataset/images/test_no_label\n",
      "15G\tDataset/images/test\n"
     ]
    }
   ],
   "source": [
    "!du -sh Dataset/images/train_no_label\n",
    "!du -sh Dataset/images/train\n",
    "!du -sh Dataset/images/validation_no_label\n",
    "!du -sh Dataset/images/validation\n",
    "!du -sh Dataset/images/test_no_label\n",
    "!du -sh Dataset/images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-env",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
