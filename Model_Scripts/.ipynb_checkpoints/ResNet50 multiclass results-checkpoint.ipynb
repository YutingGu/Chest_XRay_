{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/sz2823/home/anaconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision as tv\n",
    "from torchvision import datasets, models, transforms\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import requests\n",
    "import io\n",
    "import csv\n",
    "import random\n",
    "from timm.data import create_dataset, create_loader\n",
    "from timm.scheduler import StepLRScheduler\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "import timm \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA (GPU) available: False\n",
      "CUDA is not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU support) is available\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "print(\"Is CUDA (GPU) available:\", is_cuda_available)\n",
    "\n",
    "# If CUDA is available, print the GPU name(s)\n",
    "if is_cuda_available:\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    print(f\"Number of GPU(s) available: {gpu_count}\")\n",
    "    for i in range(gpu_count):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testidation set size: 25726\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m test_dataset\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# create data loaders \u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m loader_test \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# check if labels are loaded as defined\u001b[39;00m\n\u001b[1;32m     49\u001b[0m test_dataset\u001b[38;5;241m.\u001b[39mreader\u001b[38;5;241m.\u001b[39mclass_to_idx\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/timm/data/loader.py:353\u001b[0m, in \u001b[0;36mcreate_loader\u001b[0;34m(dataset, input_size, batch_size, is_training, no_aug, re_prob, re_mode, re_count, re_split, train_crop_mode, scale, ratio, hflip, vflip, color_jitter, color_jitter_prob, grayscale_prob, gaussian_blur_prob, auto_augment, num_aug_repeats, num_aug_splits, interpolation, mean, std, num_workers, distributed, crop_pct, crop_mode, crop_border_pixels, collate_fn, pin_memory, fp16, img_dtype, device, use_prefetcher, use_multi_epochs_loader, persistent_workers, worker_seeding, tf_preprocessing)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_prefetcher:\n\u001b[1;32m    352\u001b[0m     prefetch_re_prob \u001b[38;5;241m=\u001b[39m re_prob \u001b[38;5;28;01mif\u001b[39;00m is_training \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_aug \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m--> 353\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[43mPrefetchLoader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfp16\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# deprecated, use img_dtype\u001b[39;49;00m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mre_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefetch_re_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mre_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mre_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mre_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mre_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mre_num_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mre_num_splits\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loader\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/timm/data/loader.py:102\u001b[0m, in \u001b[0;36mPrefetchLoader.__init__\u001b[0;34m(self, loader, mean, std, channels, device, img_dtype, fp16, re_prob, re_mode, re_count, re_num_splits)\u001b[0m\n\u001b[1;32m    100\u001b[0m     img_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat16\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dtype \u001b[38;5;241m=\u001b[39m img_dtype\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(normalization_shape)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    105\u001b[0m     [x \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m std], device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mimg_dtype)\u001b[38;5;241m.\u001b[39mview(normalization_shape)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m re_prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "# config \n",
    "input_size = 3, 224, 224\n",
    "img_size = 224\n",
    "num_classes = 8\n",
    "batch_size = 128\n",
    "\n",
    "interpolation = 'bicubic'\n",
    "DEFAULT_CROP_PCT = 1\n",
    "\n",
    "test_dir = '/rds/general/user/sz2823/home/ML_project/Chest_XRay_Classification/Dataset_old/images/test_caseonly_grouped'\n",
    "class_map = {\n",
    "    'Fluid_overload': 0,\n",
    "    'Infection': 1,\n",
    "    'Mass_Like_Lesions': 2,\n",
    "    'Parenchymal_Disease': 3,\n",
    "    'Atelectasis': 4,\n",
    "    'Cardiomegaly': 5,\n",
    "    'Pneumothorax': 6,\n",
    "    'Pleural_Thickening': 7\n",
    "    }\n",
    "\n",
    "# create the train and etest datasets\n",
    "test_dataset = create_dataset(name='', root=test_dir, split='validation', is_training=False, batch_size=batch_size, class_map = class_map)\n",
    "\n",
    "test_len = len(test_dataset)\n",
    "print('testidation set size: ' + str(test_len))\n",
    "\n",
    "# resize images to fit the input of pretrained model\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.CenterCrop((224*3, 224*3)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "test_dataset.transform = transform\n",
    "\n",
    "# create data loaders \n",
    "loader_test = create_loader(\n",
    "        test_dataset,\n",
    "        input_size=input_size,\n",
    "        batch_size=batch_size,\n",
    "        is_training=False,\n",
    "        interpolation=interpolation,\n",
    "        num_workers=8,\n",
    "        pin_memory=True)\n",
    "\n",
    "# check if labels are loaded as defined\n",
    "test_dataset.reader.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the ResNet50 Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device) # if print 'cuda' then GPU is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'resnet50.a1_in1k'\n",
    "num_classes = 8\n",
    "\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=num_classes) #, img_size=img_size)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_save_path = '/rds/general/user/sz2823/home/ML_project/Chest_XRay_Classification/Sunny/model_result/model_checkpoint/MODEL_CKPT_11_resnet50.a1_in1k_20240426_161059'\n",
    "checkpoint = torch.load(ckpt_save_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.empty((0,))\n",
    "test_predictions = np.empty((0,))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(loader_test):\n",
    "        images = images.to(device)\n",
    "        labels = labels.cpu().numpy()\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        predictions = predictions.cpu().numpy()\n",
    "\n",
    "        test_labels = np.concatenate((test_labels, labels))\n",
    "        test_predictions = np.concatenate((test_predictions, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values and their counts\n",
    "unique_values, counts = np.unique(test_labels, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values and their counts\n",
    "unique_values, counts = np.unique(test_predictions, return_counts=True)\n",
    "\n",
    "# Print unique values and their counts\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"{value}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Confusion matrix4\n",
    "conf_matrix = confusion_matrix(test_labels, test_predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report\n",
    "class_report = classification_report(test_labels, test_predictions)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert true labels and predicted labels to binary format\n",
    "test_labels_binary = label_binarize(test_labels, classes=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "test_predictions_binary = label_binarize(test_predictions, classes=[0, 1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "# Compute OvR AUC\n",
    "ovr_auc = roc_auc_score(test_labels_binary, test_predictions_binary, average='macro')\n",
    "print(\"OvR AUC:\", ovr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute OvR AUC for each class\n",
    "class_auc_scores = []\n",
    "for i in range(len(test_labels_binary[0])):\n",
    "    class_test_labels = test_labels_binary[:, i]\n",
    "    class_test_predictions = test_predictions_binary[:, i]\n",
    "    class_auc = roc_auc_score(class_test_labels, class_test_predictions)\n",
    "    class_auc_scores.append(class_auc)\n",
    "\n",
    "# Print AUC for each class\n",
    "for i, auc_score in enumerate(class_auc_scores):\n",
    "    print(f\"Class {i}: AUC = {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-env",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
