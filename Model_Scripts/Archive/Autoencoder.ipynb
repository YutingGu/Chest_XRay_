{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportOwnDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(root_dir, cls)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                try:\n",
    "                    img = Image.open(img_path)\n",
    "                    # Check if the image is not truncated\n",
    "                    img.verify()\n",
    "                    self.images.append(img_path)\n",
    "                    self.labels.append(self.class_to_idx[cls])\n",
    "                except Exception as e:\n",
    "                    print(f\"Skipping {img_path}: {e}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Ensure RGB mode\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = ImportOwnDataset(root_dir='../Dataset/images/train', transform=transform)\n",
    "val_dataset = ImportOwnDataset(root_dir='../Dataset/images/validation', transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True).to(device)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(3 * 224 * 224, encoding_dim)\n",
    "        self.decoder = nn.Linear(encoding_dim, 3 * 224 * 224)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.encoder(x))\n",
    "        x = torch.sigmoid(self.decoder(x))\n",
    "        x = x.view(x.size(0), 3, 224, 224)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and send to device\n",
    "encoding_dim = 32\n",
    "autoencoder = Autoencoder(encoding_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Move model to GPU\n",
    "    autoencoder.cuda()\n",
    "\n",
    "    # Move data tensors to GPU\n",
    "    #data_tensor = data_tensor.cuda()\n",
    "\n",
    "    # Check the device of model parameters\n",
    "    for name, param in autoencoder.named_parameters():\n",
    "        print(f\"Parameter {name} is on device: {param.device}\")\n",
    "\n",
    "    # Check the device of data tensor\n",
    "    print(f\"loader_train is on device: {train_loader.device}\")\n",
    "    print(f\"loader_val is on device: {val_loader.device}\")\n",
    "\n",
    "else:\n",
    "    print(\"CUDA (GPU) is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "current_datetime = datetime.now()\n",
    "date_time = str(current_datetime)[:-7].replace('-','').replace(':','').replace(' ','_')\n",
    "model_name = 'Autoencoder'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_log_writer(s, end='\\r'):\n",
    "    with open(f'model_result/log/output_{model_name}_{date_time}.txt', 'a') as output_file:\n",
    "        output_file.write(s+'\\n')\n",
    "        print(s,end,flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    output_log_writer(f'-------------------------------[Epoch {epoch+1}]---------------------------------')\n",
    "    output_log_writer(f'[Epoch {epoch+1}] Training...', end='')\n",
    "    autoencoder.train()\n",
    "    running_loss = 0.0\n",
    "    for images, _ in train_loader:\n",
    "        print('=', end='')\n",
    "        images = images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(images)\n",
    "        \n",
    "        output_log_writer(f'[Epoch {epoch+1}] Computing Train Loss...')\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader)}\")\n",
    "    \n",
    "    # save model checkpoint\n",
    "    ckpt_save_path = f'model_result/model_checkpoint/MODEL_CKPT_{epoch}_{model_name}_{date_time}.pt'\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': losses[-2],\n",
    "            }, ckpt_save_path)\n",
    "    output_log_writer(f'[Epoch {epoch+1}] Model checkpoint is saved.')\n",
    "\n",
    "# Save model\n",
    "torch.save(autoencoder, f'model_result/model_pth/MODEL_{model_name}_{date_time}.pth')\n",
    "print('Autoencoder training complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-env",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
