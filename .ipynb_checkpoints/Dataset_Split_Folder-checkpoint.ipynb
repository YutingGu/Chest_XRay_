{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into train/val/test folders\n",
    "There is no label information included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'Dataset/images'\n",
    "train_dir_nl = 'Dataset/images/train_no_label'\n",
    "val_dir_nl = 'Dataset/images/validation_no_label'\n",
    "test_dir_nl = 'Dataset/images/test_no_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels  = open('Dataset/train_list.txt').read().split('\\n')\n",
    "val_labels  = open('Dataset/val_list.txt').read().split('\\n')\n",
    "test_labels  = open('Dataset/test_list.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existed path Dataset/images/train_no_label\n",
      "Existed path Dataset/images/validation_no_label\n",
      "Existed path Dataset/images/test_no_label\n"
     ]
    }
   ],
   "source": [
    "# creating path to store images in folders(train/val/test)\n",
    "for path in [train_dir_nl, val_dir_nl, test_dir_nl]:\n",
    "    if os.path.exists(path)== False:\n",
    "        print('Creating ',path)\n",
    "        os.makedirs(path)\n",
    "    else: print('Existed path', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(source_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfiles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalidation_no_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m files\n",
      "\u001b[0;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "files.remove('validation_no_label')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/75725 [00:00<00:34, 2182.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/images/validation_no_label\n",
      "Dataset/images/train_no_label/validation_no_label\n",
      "Dataset/images/00002658_001.png\n",
      "Dataset/images/validation_no_label/00002658_001.png\n",
      "Dataset/images/00009551_019.png\n",
      "Dataset/images/test_no_label/00009551_019.png\n",
      "Dataset/images/00006674_004.png\n",
      "Dataset/images/test_no_label/00006674_004.png\n",
      "Dataset/images/00021901_006.png\n",
      "Dataset/images/train_no_label/00021901_006.png\n",
      "Dataset/images/00012834_100.png\n",
      "Dataset/images/test_no_label/00012834_100.png\n",
      "Dataset/images/00022572_019.png\n",
      "Dataset/images/test_no_label/00022572_019.png\n",
      "Dataset/images/00016773_001.png\n",
      "Dataset/images/train_no_label/00016773_001.png\n",
      "Dataset/images/00006744_000.png\n",
      "Dataset/images/train_no_label/00006744_000.png\n",
      "Dataset/images/00017785_000.png\n",
      "Dataset/images/train_no_label/00017785_000.png\n",
      "Dataset/images/00024505_000.png\n",
      "Dataset/images/train_no_label/00024505_000.png\n",
      "Dataset/images/00015214_015.png\n",
      "Dataset/images/train_no_label/00015214_015.png\n",
      "Dataset/images/00011167_000.png\n",
      "Dataset/images/train_no_label/00011167_000.png\n",
      "Dataset/images/00012057_006.png\n",
      "Dataset/images/train_no_label/00012057_006.png\n",
      "Dataset/images/00019407_010.png\n",
      "Dataset/images/validation_no_label/00019407_010.png\n",
      "Dataset/images/00021770_002.png\n",
      "Dataset/images/train_no_label/00021770_002.png\n",
      "Dataset/images/00013695_003.png\n",
      "Dataset/images/validation_no_label/00013695_003.png\n",
      "Dataset/images/00005457_008.png\n",
      "Dataset/images/train_no_label/00005457_008.png\n",
      "Dataset/images/00029408_001.png\n",
      "Dataset/images/train_no_label/00029408_001.png\n",
      "Dataset/images/00007223_000.png\n",
      "Dataset/images/train_no_label/00007223_000.png\n",
      "Dataset/images/00020935_000.png\n",
      "Dataset/images/train_no_label/00020935_000.png\n",
      "Dataset/images/00013670_079.png\n",
      "Dataset/images/test_no_label/00013670_079.png\n",
      "Dataset/images/00006653_027.png\n",
      "Dataset/images/train_no_label/00006653_027.png\n",
      "Dataset/images/00013408_016.png\n",
      "Dataset/images/train_no_label/00013408_016.png\n",
      "Dataset/images/00001498_000.png\n",
      "Dataset/images/train_no_label/00001498_000.png\n",
      "Dataset/images/00019612_000.png\n",
      "Dataset/images/train_no_label/00019612_000.png\n",
      "Dataset/images/00008649_012.png\n",
      "Dataset/images/train_no_label/00008649_012.png\n",
      "Dataset/images/00013464_001.png\n",
      "Dataset/images/train_no_label/00013464_001.png\n",
      "Dataset/images/00029385_003.png\n",
      "Dataset/images/train_no_label/00029385_003.png\n",
      "Dataset/images/00021972_007.png\n",
      "Dataset/images/test_no_label/00021972_007.png\n",
      "Dataset/images/00018574_018.png\n",
      "Dataset/images/train_no_label/00018574_018.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(source_dir)\n",
    "n = 0\n",
    "for file in tqdm(files):\n",
    "    source_file = os.path.join(source_dir, file)\n",
    "    \n",
    "    if file in val_labels:\n",
    "        destination_file = os.path.join(val_dir_nl, file)\n",
    "\n",
    "    elif file in test_labels:\n",
    "        destination_file = os.path.join(test_dir_nl, file)\n",
    "    else:\n",
    "        destination_file = os.path.join(train_dir_nl, file)\n",
    "    \n",
    "    print(source_file)\n",
    "    print(destination_file)        \n",
    "    #shutil.move(source_file, destination_file)\n",
    "    n += 1 \n",
    "    if n > 30: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset into class-label folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv('Dataset/train_label.csv', index_col=False)\n",
    "val_label = pd.read_csv('Dataset/val_label.csv', index_col=False)\n",
    "test_label = pd.read_csv('Dataset/test_label.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_map = train_label.set_index('FileName').to_dict(orient='index')\n",
    "val_label_map = val_label.set_index('FileName').to_dict(orient='index')\n",
    "test_label_map = test_label.set_index('FileName').to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'Dataset/images/train'\n",
    "val_dir = 'Dataset/images/validation'\n",
    "test_dir = 'Dataset/images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete folders because for debugging.\n",
    "# DON'T run this cell unless you are sure you want to delete images and resplit images\n",
    "#!rm -rf Dataset/images/train\n",
    "#!rm -rf Dataset/images/validation\n",
    "#!rm -rf Dataset/images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating  Dataset/images/train/Normal\n",
      "Creating  Dataset/images/train/Atelectasis\n",
      "Creating  Dataset/images/train/Cardiomegaly\n",
      "Creating  Dataset/images/train/Effusion\n",
      "Creating  Dataset/images/train/Infiltration\n",
      "Creating  Dataset/images/train/Mass\n",
      "Creating  Dataset/images/train/Nodule\n",
      "Creating  Dataset/images/train/Pneumonia\n",
      "Creating  Dataset/images/train/Pneumothorax\n",
      "Creating  Dataset/images/train/Consolidation\n",
      "Creating  Dataset/images/train/Edema\n",
      "Creating  Dataset/images/train/Emphysema\n",
      "Creating  Dataset/images/train/Fibrosis\n",
      "Creating  Dataset/images/train/Pleural_Thickening\n",
      "Creating  Dataset/images/train/Hernia\n",
      "Creating  Dataset/images/validation/Normal\n",
      "Creating  Dataset/images/validation/Atelectasis\n",
      "Creating  Dataset/images/validation/Cardiomegaly\n",
      "Creating  Dataset/images/validation/Effusion\n",
      "Creating  Dataset/images/validation/Infiltration\n",
      "Creating  Dataset/images/validation/Mass\n",
      "Creating  Dataset/images/validation/Nodule\n",
      "Creating  Dataset/images/validation/Pneumonia\n",
      "Creating  Dataset/images/validation/Pneumothorax\n",
      "Creating  Dataset/images/validation/Consolidation\n",
      "Creating  Dataset/images/validation/Edema\n",
      "Creating  Dataset/images/validation/Emphysema\n",
      "Creating  Dataset/images/validation/Fibrosis\n",
      "Creating  Dataset/images/validation/Pleural_Thickening\n",
      "Creating  Dataset/images/validation/Hernia\n",
      "Creating  Dataset/images/test/Normal\n",
      "Creating  Dataset/images/test/Atelectasis\n",
      "Creating  Dataset/images/test/Cardiomegaly\n",
      "Creating  Dataset/images/test/Effusion\n",
      "Creating  Dataset/images/test/Infiltration\n",
      "Creating  Dataset/images/test/Mass\n",
      "Creating  Dataset/images/test/Nodule\n",
      "Creating  Dataset/images/test/Pneumonia\n",
      "Creating  Dataset/images/test/Pneumothorax\n",
      "Creating  Dataset/images/test/Consolidation\n",
      "Creating  Dataset/images/test/Edema\n",
      "Creating  Dataset/images/test/Emphysema\n",
      "Creating  Dataset/images/test/Fibrosis\n",
      "Creating  Dataset/images/test/Pleural_Thickening\n",
      "Creating  Dataset/images/test/Hernia\n"
     ]
    }
   ],
   "source": [
    "# creating path to store images in folders(train/val/test) with subfolders named by class-label\n",
    "for path in [train_dir, val_dir, test_dir]:\n",
    "    for label in ['Normal'] + list(train_label.columns[1:]): \n",
    "        path_label = path + '/' + label\n",
    "        if os.path.exists(path_label)== False:\n",
    "            print('Creating ',path_label)\n",
    "            os.makedirs(path_label)\n",
    "        else: print('Existed path', path_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_label_pair = [(train_dir_nl,train_dir,train_label_map),\n",
    "                  (val_dir_nl,val_dir,val_label_map),\n",
    "                  (test_dir_nl,test_dir,test_label_map)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying Dataset/images/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 5405/75770 [02:37<32:15, 36.35it/s]"
     ]
    }
   ],
   "source": [
    "for path_nl, path, label_map in path_label_pair:\n",
    "    print('Copying '+path)\n",
    "    files = os.listdir(path_nl)\n",
    "    for file in tqdm(files):\n",
    "        label_dict = label_map[file]\n",
    "        source_file = os.path.join(path_nl, file)\n",
    "        \n",
    "        # images without any diagnosis\n",
    "        if sum(label_map[file].values()) == 0:\n",
    "            path_label = path + '/Normal'\n",
    "            destination_file = os.path.join(path_label, file)\n",
    "            shutil.copy(source_file, destination_file)\n",
    "\n",
    "        # images with diagnosis\n",
    "        for class_label, class_index in label_dict.items():\n",
    "            if class_index == 1:\n",
    "                path_label = path + '/' + class_label\n",
    "                destination_file = os.path.join(path_label, file)\n",
    "                shutil.copy(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30G\tDataset/images/train_no_label\n",
      "16K\tDataset/images/train\n",
      "4.3G\tDataset/images/validation_no_label\n",
      "16K\tDataset/images/validation\n",
      "10G\tDataset/images/test_no_label\n",
      "16K\tDataset/images/test\n"
     ]
    }
   ],
   "source": [
    "!du -sh Dataset/images/train_no_label\n",
    "!du -sh Dataset/images/train\n",
    "!du -sh Dataset/images/validation_no_label\n",
    "!du -sh Dataset/images/validation\n",
    "!du -sh Dataset/images/test_no_label\n",
    "!du -sh Dataset/images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base-env",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
